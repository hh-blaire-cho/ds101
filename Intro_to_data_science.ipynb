{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "\n",
    "> [Source](http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram)\n",
    "\n",
    "<img src=\"Image/whatDoesDSdo.PNG\" width=\"800\" />\n",
    "\n",
    "As a \"Data Scientist\" you'll be combining your domain knowledge \"science\", with large amounts of data, using programming and computers. Your tasks as Data Scientists will involve, highly technical tasks like Machine Learning to boring and repetitive operative tasks like scraping a website from data and importing it in a Database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "\n",
    "## 1. 데이터 분석의 단계별 목적 이해하기 (분석 싸이클 이해)\n",
    "\n",
    "> [Source from recommended article](https://cacm.acm.org/blogs/blog-cacm/169199-data-science-workflow-overview-and-challenges/fulltext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 데이터 분석 과정 (책에서는 이렇게 알려주지요)\n",
    "\n",
    "1. **데이터수집**: 소스별 데이터 추출 및 저장(Loading)\n",
    "2. **데이터전처리**: 기초통계(Descriptive Statistics) + 붙이기(Curation) + 없애기(Remove) + 채우기(Fill) + 필터(Filter) + 변경하기(Transform)\n",
    "3. **데이터정리**: 데이터한곳에담기(Data Warehouse) + 바꾸기및정리(Data Mart) + 분리(Data Split)\n",
    "4. **데이터분석**: 기초통계(Descriptive Statistics) + 모델링(Algorithm) + 검증(Evaluation) + 에러분석(Error Analysis)\n",
    "5. **결과정리**: 시각화(Visualization/Dashboard) + 의사결정(Decision Support) + 지식화(Knowledge) + 공유(Reporting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 데이터 분석 과정 (또 다른 책에서는, in english)\n",
    "\n",
    "1.  ** Getting the data**\n",
    "</br> Depending on your company/organization, getting the data can be as simple as a SQL query or as difficult as scraping entire websites. The problem with this task is that it's not standardized.\n",
    "\n",
    "2. ** Parsing and Cleaning the Data**\n",
    "</br> Depending on your sources, you'll need to do a little bit of preparation. Excluding outliers, filling null values, translating values, etc.\n",
    "\n",
    "3. ** Merging, combining data**\n",
    "</br> If the data comes from different sources, merging it can be tedious. Specially if it's hard to define that piece of information that relates different data sources.\n",
    "\n",
    "4. ** Doing the analysis**\n",
    "</br> This involves your own domain expertise + the tools available for the job. For example, you need to know the principles of statistics and you can also use [`statsmodels`](https://www.statsmodels.org) to simplify your job. The analysis part is usually iterative and involves other subtasks as visualizations, validation testing, etc.\n",
    "\n",
    "5. ** Building models**\n",
    "</br> The whole point of the analysis part is finding patterns in particular cases to build general models. Your models can be predictions, clusterings, or just automated reports. In a general sense, it's the result of all the previous phases.\n",
    "\n",
    "6. ** Deploying it**\n",
    "</br> Perfect analyses and models are useless if they're not repeatable and scalable. This phase depends on your own models, but it'll usually imply a cloud provider. From simple reports (emailed every day at 3AM from an AWS Lambda) to a Machine Learning Model (built on top of Tensor Flow and deployed on Google's cloud infrastructure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "\n",
    "## 2. 데이터 분석의 이상/현실/실무 관점?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 데이터 싸이언티스트?/애널리스트?/엔지니어?/비즈니스고객? 관점에서:\n",
    "\n",
    "\n",
    "<img src='Image/AnalysisCycle1.png' width='800'>\n",
    "<img src='Image/AnalysisCycle2.png' width='800'>\n",
    "<img src='Image/AnalysisCycle3.png' width='800'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 현실 관점에서:\n",
    "\n",
    "<img src='Image/Analysis_Real1.PNG' width='800'>\n",
    "<img src='Image/Analysis_Real2.PNG' width='800'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 데이터 분석 현실 요약:\n",
    "\n",
    "<img src='Image/Analysis_Process.png' width='800'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **예시1)** “퇴사할 사람을 찾아주세요”  vs  “입사할 사람을 찾아주세요“\n",
    "- **예시2)** “삼성전자 주식을 사야 할까요 말아야 할까요?”  vs  “내일 삼성전자 주식은 얼마일까요?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실전에서는 이런 질문을 받았을 때, 바로 컴퓨터를 켜서 딥러닝을 돌리는 것이 아니다!</br>\n",
    "회사에 있는 데이터를 몽땅 긁어다가, string은 string으로 분류, numbers는 numbers로 분류한 후 가장 있어보이는 알고리즘을 입히는 것이 절대 아니다.\n",
    "\n",
    "질문을 던지는 것 자체는 쉽지. 이것을 현실적인 단계에서 질문을 어떻게 풀어나가야 하나? 이것이 진짜 문제.</br>\n",
    "이때 많은 소통과 domain knowledge, 기획, 평가가 필요한 것 </br> \n",
    "도대체 퇴사할 사람의 정의가 무엇인가. A4용지를 많이 쓰는 사람? 칼퇴를 하는 사람? 핸드폰을 자주 보는 사람? </br>\n",
    "\n",
    "많은 소통/기획/평가를 해보니 퇴사할 사람의 정의란 참 애매모호하고 데이터도 없다. 그래서 문제를 바꾸어 보기로 한다. 바로 회사에 불만이 있는 사람이다. </br>\n",
    "그리고 회사에 불만이 있는 사람은 다음과 같은 시그널이 있다는 것을 알았다. 불만의 정의를 파악했고, 불만이 있는 사람의 패턴을 분석했기 때문이다. \n",
    " - 상사와 자주 싸운다.\n",
    " - 일에 집중하지 못한다.\n",
    " - 자리를 자주 비운다.\n",
    " - 회사 욕을 한다.\n",
    "\n",
    "이제 X로서 어떤 데이터를 쓰면 될 지를 알았으니, X를 수집하고 알고리즘을 무엇을 쓸 지 알아보는 단계로 넘어간다. 바로 2단계의 f를 찾는 것. 이것 또한 많은 고민이 필요하다. 회사에 불만이 있다 없다 0, 1로만 나눌 것인지. 아님 0~100으로 볼 것인지도 정해야 하니까...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`**데이터 분석 설계(1단계)**` 는 모델링(2단계)보다 훨씬 중요합니다. 그리고 분석종료(3단계)는 또다른 새로운 시작입니다\n",
    "- 1단계조차도 현실에선 매우 어렵다. 1단계가 만약 잘못되었다면, 이후 해놓은 2, 3단계가 의미가 없어진다.\n",
    "- 2단계만 하는 것은 책에 있는 (또는 캐글에 있는) 예제를 하나 푼 것이지. 데이터 분석을 한 것이 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 데이터 분석 현실 과정:\n",
    "\n",
    "- **요구사항(질문) 예시:**\n",
    "> - \"아이폰 고객은 왜 갤럭시 고객보다 충성도가 높은지 분석해봐~\" 라고 질문을 다 듣기도/이해하기도/생각하기도 전에 프로젝트가 시작됩니다\n",
    "> - \"AI를 활용해서 생산공정의 이상을 조기 탐지하고 비용을 줄여봐~\" 라고 질문을 다 듣기도/이해하기도/생각하기도 전에 프로젝트가 시작됩니다 \n",
    "> - \"타겟 마케팅을 하기위해 누구한테 프로모션을 해야하는지 알려줘봐~\" 라고 질문을 다 듣기도/이해하기도/생각하기도 전에 프로젝트가 시작됩니다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. **문제정의**: 무엇을 분석할지 정한다\n",
    "    > 무엇을 분석할지 각자 생각이 모두 다르다(솔직히 아무도 모른다)  \n",
    "    > 무엇을 분석할지 모르지만 일단 도구(R? Python? 플랫폼? 아마존? 외주?)부터 마련한다  \n",
    "    > 무엇을 분석할지 모르지만 완료일정과 계획이 준비가 되어있다  \n",
    "    > 어쨌건 있다고 생각하고 시작한다  \n",
    "    > (데이터분석 프로젝트는 이미 착수했다고 보고가 되었다)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **데이터수집**: ~~소스별 데이터 추출 및 저장(Loading)~~\n",
    "    > 데이터 PC에 있는줄 알았는데 A4용지에 있어서 누구 시켜서 파일로 바꾼다    \n",
    "    > 데이터를 구했는데 빅데이터는 아니고 그냥 엑셀 파일 몇개다  \n",
    "    > 데이터 파일을 열었더니 다 빈칸이고 딱봐도 오타 투성이다  \n",
    "    > 근데 이 데이터로 충분한지 아무도 모르지만 어쨌건 (있는줄/충분한줄 알았는데) 시작한다  \n",
    "    > (빅데이터를 기반으로 한 데이터 수집이 완료가 되었다고 보고가 되었다)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **데이터전처리**: ~~기초통계(Descriptive Statistics) + 붙이기(Curation) + 없애기(Remove) + 채우기(Fill) + 필터(Filter) + 변경하기(Transform)~~\n",
    "    > 무엇을 분석할지 모르고 데이터는 없지만 전처리에 돌입한다  \n",
    "    > 일단 이상해 보이는 데이터를 다 지워본다 (남는게 없다..)  \n",
    "    > 임의로 데이터를 채워본다 (어짜피 아무도 모르니까..)\n",
    "    > 할게 많을 줄 알았는데 별로 할게 없음을 깨닿는다  \n",
    "    > (데이터가 무결점으로 잘 준비되어 있다고 보고가 되었다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **데이터정리**: ~~데이터한곳에담기(Data Warehouse) + 바꾸기및정리(Data Mart) + 분리(Data Split)~~\n",
    "    > (대부분 개인PC로 충분하겠지만) 일단 서버/플랫폼에 데이터를 올린다  \n",
    "    > (뭔가 중요한걸 해야할것 같은데..) 서버/플랫폼 사양정도 체크해보며 있는다  \n",
    "    > (데이터 플랫폼에 데이터가 이관되고 곧 분석에 착수할거라고 보고가 되었다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **데이터분석**: ~~기초통계(Descriptive Statistics) + 모델링(Algorithm) + 검증(Evaluation) + 에러분석(Error Analysis)~~\n",
    "    > 무엇을 분석하고 무슨 데이터를 사용해야 되는지 모르지만 분석을 시작한다  \n",
    "    > 기초통계는 사람수?클릭수? 등 \"횟수(count)\"면 충분하다  \n",
    "    > 도구(R? Python? 플랫폼? 아마존? 외주?) 활용/쪼아서 제일 최신 알고리즘을 적용해보려 살펴본다  \n",
    "    > (뭔가 안되면..) 우선 1차 회귀분석? 상관관계? 어디서 들어본걸 해서 그림부터 그려본다  \n",
    "    > (뭔가 중요한 단계인것 같은데..) 더이상 할수 있는게 없음을 깨닿는다  \n",
    "    > (분석이 완료되어 인싸이트가 곧 쏟아질 것이라고 보고가 되었다)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **결과정리**: ~~시각화(Visualization/Dashboard) + 의사결정(Decision Support) + 지식화(Knowledge) + 공유(Reporting)~~\n",
    "    > 무엇을 분석하고 무슨 데이터를 사용하고 무슨 결과가 있는진 모르겠지만 결과를 정리한다  \n",
    "    > (완료일정이 내일이라 퇴사/퇴학이 필요한게 아닌지 잠이 오지 않는다)  \n",
    "    > (신기한건 모든 단계는 작동/구현되었고 각 단계 개발자들은 성과를 보고한다)  \n",
    "    > (Kaggle과 데이터분석은 다름을 알게된다)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.3 실무 관점에서:\n",
    "\n",
    "<center><img src='Image/Analysis_Cycle.png' width='800'></center>\n",
    "\n",
    "0. **문제정의**: 무엇을 분석할지 정한다\n",
    "    - 문제정의가 없으면 분석은 시작할 필요가 없다  \n",
    "        > **문제정의에 많은 고민을 해야 한다**  \n",
    "        > **문제정의에 모든 구성원이 동의할 수 있도록 끊임없이 커뮤니케이션 해야 한다**  \n",
    "        > **1회성이 문제정의가 아니라 필요시 끊임없이 진화/변경시켜야 한다**  \n",
    "\n",
    "1. **데이터수집**: 소스별 데이터 추출 및 저장(Loading)\n",
    "    - 데이터가 없으면 분석은 시작할 필요가 없다\n",
    "    - 문제 답의 보기후보가 데이터에 없으면 분석을 시작할 필요가 없다(어떤 연령이 TV를 보는지 알고 싶은데 데이터에 연령이 없으면 불가)\n",
    "        > **알고리즘/기술보다 데이터수집부터 시작하기 위한 작업을 착수해야 한다**\n",
    "        > **데이터는 많을수록 좋지만 양보다(Row) 질(Column)을 늘려야 분석을 한 의미가 생긴다**\n",
    "        > **보기가 데이터에 없으면 문제정의부터 새롭게 수정해야 한다**\n",
    "        > - Loading 목적: 각 소스별로 데이터를 수집함\n",
    "    \n",
    "2. **데이터전처리**: 기초통계(Descriptive Statistics) + 붙이기(Curation) + 없애기(Remove) + 채우기(Fill) + 필터(Filter) + 변경하기(Transform)  \n",
    "    > - Descriptive Statistics 목적: 하기 4개의 전처리 의사결정을 위한 기준으로 주로 활용\n",
    "    > - Curation 목적: 각 소스별 데이터를 하나의 Database로 붙임  \n",
    "    > - Remove & Fill 목적: 데이터 오류를 제거하가나 비어있는 데이터를 채움  \n",
    "    > - Filter 목적: 분석범위에 관련된 보기(Feature)들만을 추려냄  \n",
    "    > - Transform 목적: 사람이 이해가 가능한 방식으로 데이터 자체를 변경함  \n",
    "    \n",
    "3. **데이터정리**: 데이터한곳에담기(Data Warehouse) + 바꾸기및정리(Data Mart) + 분리(Data Split)\n",
    "    - 데이터수집/전처리/정리 까지 전체 업무의 80% 이상을 차지한다\n",
    "        > **1회성 수집/전저리/정리로 끝나지 않고 끊임없이 업데이트하고 진화시켜야 한다(이는 분석알고리즘이 해주지 않는다)**  \n",
    "        > - Data Warehouse 목적: 전처리 단계를 거친 1개의 Database를 주로 보관 및 무결점 유지 목적\n",
    "        > - Data Mart 목적: Warehouse를 변경하지 않고 복사하여 조금 더 목적에 맞게 전처리를 거침\n",
    "        > - Data Split 목적: 주로 과거(Train Data)와 미래(Test Data)를 구분하여 저장/알고리즘에 활용\n",
    "    \n",
    "4. **데이터분석**: 기초통계(Descriptive Statistics) + 모델링(Algorithm) + 검증(Evaluation) + 에러분석(Error Analysis)  \n",
    "    - 수학적으론 어려울 수 있지만 수동적으로 대응/활용이 가능하다\n",
    "    - 알고리즘(또는 기계)은 정해진 검증수단을 따를뿐 우리의 문제에 관심이 없다\n",
    "        > **각 알고리즘의 사용 목적에 대한 명확한 이해와 결과해석을 집중해서 습득해야 한다**  \n",
    "        > **어떤 알고리즘 성능 뛰어난지 검증(Evaluation)은 결국 사람이기에 많은 고민을 해야 한다**\n",
    "        > **알고리즘 적용시작이 중요한게 아니라 언제 끝내야 하는지 고민해야 한다**\n",
    "        > - Descriptive Statistics 목적: 어떤 분석 알고리즘을 선정할지 또는 Input/Output 형태를 결정하는 기준으로 활용\n",
    "        > - Algorithm 목적: Input/Output의 형태 또는 분석목적에 따라 정해지는 편\n",
    "        > - Evaluation 목적: 현 알고리즘 성능 확인 및 다음 업데이트를 위한 기준 설정\n",
    "        > - Error Analysis 목적: 모든 데이터의 패턴/특징을 알고리즘이 반영하고 있음을 이해하기 위한 기준\n",
    "    \n",
    "5. **결과정리**: 시각화(Visualization/Dashboard) + 의사결정(Decision Support) + 지식화(Knowledge) + 공유(Reporting)\n",
    "    > **0~4 단계를 무한대로 반복 및 각 단계를 업데이트하며 인싸이트를 뽑아낼 수 있어야 한다**\n",
    "    > - Visualization/Dashboard/Decision/Knowledge/Reporting 목적: 주로 고객에 맞춘 설명력을 제공하기 위함으로 일반화된 방향은 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "\n",
    "## 3. 데이터 분석 툴 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- numpy\n",
    "- pandas\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- beautifulsoup\n",
    "- scikit-learn"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1058px",
    "left": "579px",
    "top": "224px",
    "width": "431.576px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
